{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b39a433b-b6ec-4bdb-a0e7-3a8f27380264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing URL_ID: blackassign0001, URL: https://insights.blackcoffer.com/rising-it-cities-and-its-impact-on-the-economy-environment-infrastructure-and-city-life-by-the-year-2040-2/\n",
      "Processing URL_ID: blackassign0002, URL: https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/\n",
      "Processing URL_ID: blackassign0003, URL: https://insights.blackcoffer.com/internet-demands-evolution-communication-impact-and-2035s-alternative-pathways/\n",
      "Processing URL_ID: blackassign0004, URL: https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-in-upcoming-future/\n",
      "Processing URL_ID: blackassign0005, URL: https://insights.blackcoffer.com/ott-platform-and-its-impact-on-the-entertainment-industry-in-future/\n",
      "Processing URL_ID: blackassign0006, URL: https://insights.blackcoffer.com/the-rise-of-the-ott-platform-and-its-impact-on-the-entertainment-industry-by-2040/\n",
      "Processing URL_ID: blackassign0007, URL: https://insights.blackcoffer.com/rise-of-cyber-crime-and-its-effects/\n",
      "Processing URL_ID: blackassign0008, URL: https://insights.blackcoffer.com/rise-of-internet-demand-and-its-impact-on-communications-and-alternatives-by-the-year-2035-2/\n",
      "Processing URL_ID: blackassign0009, URL: https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-by-the-year-2040-2/\n",
      "Processing URL_ID: blackassign0010, URL: https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-by-the-year-2040/\n",
      "Processing URL_ID: blackassign0011, URL: https://insights.blackcoffer.com/rise-of-internet-demand-and-its-impact-on-communications-and-alternatives-by-the-year-2035/\n",
      "Processing URL_ID: blackassign0012, URL: https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-3-2/\n",
      "Processing URL_ID: blackassign0013, URL: https://insights.blackcoffer.com/rise-of-e-health-and-its-impact-on-humans-by-the-year-2030/\n",
      "Processing URL_ID: blackassign0014, URL: https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030-2/\n",
      "Processing URL_ID: blackassign0015, URL: https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2/\n",
      "Processing URL_ID: blackassign0016, URL: https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2-2/\n",
      "Processing URL_ID: blackassign0017, URL: https://insights.blackcoffer.com/rise-of-chatbots-and-its-impact-on-customer-support-by-the-year-2040/\n",
      "Processing URL_ID: blackassign0018, URL: https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030/\n",
      "Processing URL_ID: blackassign0019, URL: https://insights.blackcoffer.com/how-does-marketing-influence-businesses-and-consumers/\n",
      "Processing URL_ID: blackassign0020, URL: https://insights.blackcoffer.com/how-advertisement-increase-your-market-value/\n",
      "Processing URL_ID: blackassign0021, URL: https://insights.blackcoffer.com/negative-effects-of-marketing-on-society/\n",
      "Processing URL_ID: blackassign0022, URL: https://insights.blackcoffer.com/how-advertisement-marketing-affects-business/\n",
      "Processing URL_ID: blackassign0023, URL: https://insights.blackcoffer.com/rising-it-cities-will-impact-the-economy-environment-infrastructure-and-city-life-by-the-year-2035/\n",
      "Processing URL_ID: blackassign0024, URL: https://insights.blackcoffer.com/rise-of-ott-platform-and-its-impact-on-entertainment-industry-by-the-year-2030/\n",
      "Processing URL_ID: blackassign0025, URL: https://insights.blackcoffer.com/rise-of-electric-vehicles-and-its-impact-on-livelihood-by-2040/\n",
      "Processing URL_ID: blackassign0026, URL: https://insights.blackcoffer.com/rise-of-electric-vehicle-and-its-impact-on-livelihood-by-the-year-2040/\n",
      "Processing URL_ID: blackassign0027, URL: https://insights.blackcoffer.com/oil-prices-by-the-year-2040-and-how-it-will-impact-the-world-economy/\n",
      "Processing URL_ID: blackassign0028, URL: https://insights.blackcoffer.com/an-outlook-of-healthcare-by-the-year-2040-and-how-it-will-impact-human-lives/\n",
      "Processing URL_ID: blackassign0029, URL: https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\n",
      "Processing URL_ID: blackassign0030, URL: https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/\n",
      "Processing URL_ID: blackassign0031, URL: https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/\n",
      "Processing URL_ID: blackassign0032, URL: https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/\n",
      "Processing URL_ID: blackassign0033, URL: https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/\n",
      "Processing URL_ID: blackassign0034, URL: https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/\n",
      "Processing URL_ID: blackassign0035, URL: https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/\n",
      "Processing URL_ID: blackassign0036, URL: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
      "Extraction failed for URL: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
      "404 Client Error: Not Found for url: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
      "Failed to extract content for URL_ID: blackassign0036\n",
      "Processing URL_ID: blackassign0037, URL: https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/\n",
      "Processing URL_ID: blackassign0038, URL: https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/\n",
      "Processing URL_ID: blackassign0039, URL: https://insights.blackcoffer.com/how-to-protect-future-data-and-its-privacy-blackcoffer/\n",
      "Processing URL_ID: blackassign0040, URL: https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/\n",
      "Processing URL_ID: blackassign0041, URL: https://insights.blackcoffer.com/ai-human-robotics-machine-future-planet-blackcoffer-thinking-jobs-workplace/\n",
      "Processing URL_ID: blackassign0042, URL: https://insights.blackcoffer.com/how-ai-will-change-the-world-blackcoffer/\n",
      "Processing URL_ID: blackassign0043, URL: https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/\n",
      "Processing URL_ID: blackassign0044, URL: https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/\n",
      "Processing URL_ID: blackassign0045, URL: https://insights.blackcoffer.com/ai-healthcare-revolution-ml-technology-algorithm-google-analytics-industrialrevolution/\n",
      "Processing URL_ID: blackassign0046, URL: https://insights.blackcoffer.com/all-you-need-to-know-about-online-marketing/\n",
      "Processing URL_ID: blackassign0047, URL: https://insights.blackcoffer.com/evolution-of-advertising-industry/\n",
      "Processing URL_ID: blackassign0048, URL: https://insights.blackcoffer.com/how-data-analytics-can-help-your-business-respond-to-the-impact-of-covid-19/\n",
      "Processing URL_ID: blackassign0049, URL: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
      "Extraction failed for URL: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
      "404 Client Error: Not Found for url: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
      "Failed to extract content for URL_ID: blackassign0049\n",
      "Processing URL_ID: blackassign0050, URL: https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/\n",
      "Processing URL_ID: blackassign0051, URL: https://insights.blackcoffer.com/how-data-analytics-and-ai-are-used-to-halt-the-covid-19-pandemic/\n",
      "Processing URL_ID: blackassign0052, URL: https://insights.blackcoffer.com/difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/\n",
      "Processing URL_ID: blackassign0053, URL: https://insights.blackcoffer.com/how-python-became-the-first-choice-for-data-science/\n",
      "Processing URL_ID: blackassign0054, URL: https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/\n",
      "Processing URL_ID: blackassign0055, URL: https://insights.blackcoffer.com/what-is-the-future-of-mobile-apps/\n",
      "Processing URL_ID: blackassign0056, URL: https://insights.blackcoffer.com/impact-of-ai-in-health-and-medicine/\n",
      "Processing URL_ID: blackassign0057, URL: https://insights.blackcoffer.com/telemedicine-what-patients-like-and-dislike-about-it/\n",
      "Processing URL_ID: blackassign0058, URL: https://insights.blackcoffer.com/how-we-forecast-future-technologies/\n",
      "Processing URL_ID: blackassign0059, URL: https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/\n",
      "Processing URL_ID: blackassign0060, URL: https://insights.blackcoffer.com/embedding-care-robots-into-society-socio-technical-considerations/\n",
      "Processing URL_ID: blackassign0061, URL: https://insights.blackcoffer.com/management-challenges-for-future-digitalization-of-healthcare-services/\n",
      "Processing URL_ID: blackassign0062, URL: https://insights.blackcoffer.com/are-we-any-closer-to-preventing-a-nuclear-holocaust/\n",
      "Processing URL_ID: blackassign0063, URL: https://insights.blackcoffer.com/will-technology-eliminate-the-need-for-animal-testing-in-drug-development/\n",
      "Processing URL_ID: blackassign0064, URL: https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/\n",
      "Processing URL_ID: blackassign0065, URL: https://insights.blackcoffer.com/will-we-ever-colonize-outer-space/\n",
      "Processing URL_ID: blackassign0066, URL: https://insights.blackcoffer.com/what-is-the-chance-homo-sapiens-will-survive-for-the-next-500-years/\n",
      "Processing URL_ID: blackassign0067, URL: https://insights.blackcoffer.com/why-does-your-business-need-a-chatbot/\n",
      "Processing URL_ID: blackassign0068, URL: https://insights.blackcoffer.com/how-you-lead-a-project-or-a-team-without-any-technical-expertise/\n",
      "Processing URL_ID: blackassign0069, URL: https://insights.blackcoffer.com/can-you-be-great-leader-without-technical-expertise/\n",
      "Processing URL_ID: blackassign0070, URL: https://insights.blackcoffer.com/how-does-artificial-intelligence-affect-the-environment/\n",
      "Processing URL_ID: blackassign0071, URL: https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/\n",
      "Processing URL_ID: blackassign0072, URL: https://insights.blackcoffer.com/is-perfection-the-greatest-enemy-of-productivity/\n",
      "Processing URL_ID: blackassign0073, URL: https://insights.blackcoffer.com/global-financial-crisis-2008-causes-effects-and-its-solution/\n",
      "Processing URL_ID: blackassign0074, URL: https://insights.blackcoffer.com/gender-diversity-and-equality-in-the-tech-industry/\n",
      "Processing URL_ID: blackassign0075, URL: https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes/\n",
      "Processing URL_ID: blackassign0076, URL: https://insights.blackcoffer.com/how-small-business-can-survive-the-coronavirus-crisis/\n",
      "Processing URL_ID: blackassign0077, URL: https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/\n",
      "Processing URL_ID: blackassign0078, URL: https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors/\n",
      "Processing URL_ID: blackassign0079, URL: https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-tourism-aviation-industries/\n",
      "Processing URL_ID: blackassign0080, URL: https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-sports-events-around-the-world/\n",
      "Processing URL_ID: blackassign0081, URL: https://insights.blackcoffer.com/changing-landscape-and-emerging-trends-in-the-indian-it-ites-industry/\n",
      "Processing URL_ID: blackassign0082, URL: https://insights.blackcoffer.com/online-gaming-adolescent-online-gaming-effects-demotivated-depression-musculoskeletal-and-psychosomatic-symptoms/\n",
      "Processing URL_ID: blackassign0083, URL: https://insights.blackcoffer.com/human-rights-outlook/\n",
      "Processing URL_ID: blackassign0084, URL: https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/\n",
      "Processing URL_ID: blackassign0085, URL: https://insights.blackcoffer.com/how-the-covid-19-crisis-is-redefining-jobs-and-services/\n",
      "Processing URL_ID: blackassign0086, URL: https://insights.blackcoffer.com/how-to-increase-social-media-engagement-for-marketers/\n",
      "Processing URL_ID: blackassign0087, URL: https://insights.blackcoffer.com/impacts-of-covid-19-on-streets-sides-food-stalls/\n",
      "Processing URL_ID: blackassign0088, URL: https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets-2/\n",
      "Processing URL_ID: blackassign0089, URL: https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-5/\n",
      "Processing URL_ID: blackassign0090, URL: https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-4/\n",
      "Processing URL_ID: blackassign0091, URL: https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-2/\n",
      "Processing URL_ID: blackassign0092, URL: https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/\n",
      "Processing URL_ID: blackassign0093, URL: https://insights.blackcoffer.com/travel-and-tourism-outlook/\n",
      "Processing URL_ID: blackassign0094, URL: https://insights.blackcoffer.com/gaming-disorder-and-effects-of-gaming-on-health/\n",
      "Processing URL_ID: blackassign0095, URL: https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation/\n",
      "Processing URL_ID: blackassign0096, URL: https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation-2/\n",
      "Processing URL_ID: blackassign0097, URL: https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-office-space-and-co-working-industries/\n",
      "Processing URL_ID: blackassign0098, URL: https://insights.blackcoffer.com/contribution-of-handicrafts-visual-arts-literature-in-the-indian-economy/\n",
      "Processing URL_ID: blackassign0099, URL: https://insights.blackcoffer.com/how-covid-19-is-impacting-payment-preferences/\n",
      "Processing URL_ID: blackassign0100, URL: https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def extract_article(url):\n",
    "    try:\n",
    "       \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for 4xx and 5xx status codes\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract the title\n",
    "        title_tag = soup.find('title')\n",
    "        title = title_tag.get_text().strip() if title_tag else 'No Title'\n",
    "        \n",
    "        # Find the content within <div> elements containing both classes 'td-post-content' and 'tagdiv-type'\n",
    "        post_content = soup.find('div', class_=lambda c: c and 'td-post-content' in c.split() and 'tagdiv-type' in c.split())\n",
    "        if not post_content:\n",
    "            return title, None\n",
    "        \n",
    "        # Extract the text from post_content\n",
    "        article_content = post_content.get_text().strip()\n",
    "        \n",
    "        return title, article_content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Extraction failed for URL: {url}\")\n",
    "        print(e)  # Print the exception for debugging\n",
    "        return None, None\n",
    "\n",
    "def save_article(url_id, title, article_content, folder_path):\n",
    "    if not article_content:\n",
    "        return\n",
    "    \n",
    "    file_name = f\"{url_id}.txt\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Open the file in write mode, which clears the existing content\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(f\"{title}\\n\\n{article_content}\")\n",
    "\n",
    "def main(input_file, folder_path):\n",
    "    df = pd.read_excel(input_file)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        url_id = row['URL_ID']\n",
    "        url = row['URL']\n",
    "        \n",
    "        print(f\"Processing URL_ID: {url_id}, URL: {url}\")\n",
    "        \n",
    "        title, article_content = extract_article(url)\n",
    "        \n",
    "        if title and article_content:\n",
    "            save_article(url_id, title, article_content, folder_path)\n",
    "        else:\n",
    "            print(f\"Failed to extract content for URL_ID: {url_id}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = 'input.xlsx'  # Assuming input.xlsx is in the same directory as the notebook\n",
    "    folder_path = 'articles'  # Current directory\n",
    "    main(input_file, folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03a8b0b1-de49-463f-81ef-8c6a35ce8dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\charm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\charm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to load stop words from multiple files\n",
    "def load_stop_words(stop_words_folder):\n",
    "    stop_words = set()\n",
    "    for file_name in os.listdir(stop_words_folder):\n",
    "        if file_name.endswith('.txt'):\n",
    "            with open(os.path.join(stop_words_folder, file_name), 'r') as file:\n",
    "                words = file.read().splitlines()\n",
    "                stop_words.update(words)\n",
    "    return stop_words\n",
    "\n",
    "# Load stop words\n",
    "stop_words_folder = 'StopWords'\n",
    "stop_words = load_stop_words(stop_words_folder)\n",
    "\n",
    "# Load punctuation\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# Function to clean and tokenize text\n",
    "def clean_and_tokenize(text, stop_words, punctuation):\n",
    "    # Tokenize text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words and punctuation\n",
    "    tokens = [word.lower() for word in tokens if word.lower() not in stop_words and word.lower() not in punctuation]\n",
    "    \n",
    "    # Stemming\n",
    "    porter = PorterStemmer()\n",
    "    tokens = [porter.stem(word) for word in tokens]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Function to load positive and negative words from multiple files\n",
    "def load_master_dictionary(master_dict_folder):\n",
    "    positive_words = set()\n",
    "    negative_words = set()\n",
    "    for file_name in os.listdir(master_dict_folder):\n",
    "        if file_name.endswith('.txt'):\n",
    "            with open(os.path.join(master_dict_folder, file_name), 'r') as file:\n",
    "                for line in file:\n",
    "                    word = line.strip()\n",
    "                    if word:\n",
    "                        if file_name.startswith('positive'):\n",
    "                            positive_words.add(word.lower())\n",
    "                        elif file_name.startswith('negative'):\n",
    "                            negative_words.add(word.lower())\n",
    "    return positive_words, negative_words\n",
    "\n",
    "# Load positive and negative words\n",
    "master_dict_folder = 'MasterDictionary'\n",
    "positive_words, negative_words = load_master_dictionary(master_dict_folder)\n",
    "\n",
    "# Function to calculate sentiment scores\n",
    "def calculate_sentiment_scores(tokens, positive_words, negative_words):\n",
    "    positive_score = sum(1 for word in tokens if word in positive_words)\n",
    "    negative_score = sum(1 for word in tokens if word in negative_words)\n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score) / (len(tokens) + 0.000001)\n",
    "    return positive_score, negative_score, polarity_score, subjectivity_score\n",
    "\n",
    "# Function to analyze readability\n",
    "def analyze_readability(text, punctuation):\n",
    "    sentences = sent_tokenize(text)\n",
    "    total_words = sum(len(word_tokenize(sentence)) for sentence in sentences)\n",
    "    total_sentences = len(sentences)\n",
    "    average_sentence_length = total_words / total_sentences\n",
    "    complex_word_count = sum(1 for sentence in sentences for word in word_tokenize(sentence) if len(word) > 2)\n",
    "    percentage_complex_words = complex_word_count / total_words\n",
    "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
    "    average_words_per_sentence = total_words / total_sentences\n",
    "    syllable_per_word = calculate_syllables_per_word(text)\n",
    "    personal_pronoun_count = calculate_personal_pronouns(text)\n",
    "    average_word_length = calculate_average_word_length(text)\n",
    "    return (average_sentence_length, percentage_complex_words, fog_index, average_words_per_sentence, complex_word_count, total_words, syllable_per_word, personal_pronoun_count, average_word_length)\n",
    "\n",
    "# Function to calculate the number of syllables in a word\n",
    "def count_syllables(word):\n",
    "    vowels = 'aeiouy'\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "# Function to calculate the number of syllables per word in the text\n",
    "def calculate_syllables_per_word(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    total_syllables = sum(count_syllables(word) for word in tokens)\n",
    "    total_words = len(tokens)\n",
    "    syllables_per_word = total_syllables / total_words\n",
    "    return syllables_per_word\n",
    "import re\n",
    "# Function to count personal pronouns in the text\n",
    "def calculate_personal_pronouns(text):\n",
    "    personal_pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    pronoun_regex = re.compile(r'\\b(?:I|we|my|ours|us)\\b', re.IGNORECASE)\n",
    "    # Find all matches in the text\n",
    "    matches = pronoun_regex.findall(text)\n",
    "    # Return the count of matches\n",
    "    personal_pronoun_count=len(matches)\n",
    "    return personal_pronoun_count\n",
    "\n",
    "# Function to calculate average word length\n",
    "def calculate_average_word_length(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    total_characters = sum(len(word) for word in tokens)\n",
    "    total_words = len(tokens)\n",
    "    average_word_length = total_characters / total_words\n",
    "    return average_word_length\n",
    "\n",
    "# Function to perform sentiment analysis and readability analysis on a given file\n",
    "def analyze_file(file_path, stop_words, punctuation, positive_words, negative_words):\n",
    "    try:\n",
    "        # Read the file content\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        # Clean and tokenize text\n",
    "        tokens = clean_and_tokenize(text, stop_words, punctuation)\n",
    "        \n",
    "        # Calculate sentiment scores\n",
    "        positive_score, negative_score, polarity_score, subjectivity_score = calculate_sentiment_scores(tokens, positive_words, negative_words)\n",
    "        \n",
    "        average_sentence_length, percentage_complex_words, fog_index, average_words_per_sentence, complex_word_count, total_words, syllable_per_word, personal_pronoun_count, average_word_length = analyze_readability(text, punctuation)\n",
    "        \n",
    "        return {\n",
    "            'POSITIVE SCORE': positive_score,\n",
    "            'NEGATIVE SCORE': negative_score,\n",
    "            'POLARITY SCORE': polarity_score,\n",
    "            'SUBJECTIVITY SCORE': subjectivity_score,\n",
    "            'AVG SENTENCE LENGTH': average_sentence_length,\n",
    "            'PERCENTAGE OF COMPLEX WORDS': percentage_complex_words,\n",
    "            'FOG INDEX': fog_index,\n",
    "            'AVG NUMBER OF WORDS PER SENTENCE': average_words_per_sentence,\n",
    "            'COMPLEX WORD COUNT': complex_word_count,\n",
    "            'WORD COUNT': total_words,\n",
    "            'SYLLABLE PER WORD': syllable_per_word,\n",
    "            'PERSONAL PRONOUNS': personal_pronoun_count,\n",
    "            'AVG WORD LENGTH': average_word_length\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to analyze file: {file_path}\")\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9871a615-3dc9-4334-a456-52e145921ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing file: articles\\blackassign0001.txt\n",
      "Analyzing file: articles\\blackassign0002.txt\n",
      "Analyzing file: articles\\blackassign0003.txt\n",
      "Analyzing file: articles\\blackassign0004.txt\n",
      "Analyzing file: articles\\blackassign0005.txt\n",
      "Analyzing file: articles\\blackassign0006.txt\n",
      "Analyzing file: articles\\blackassign0007.txt\n",
      "Analyzing file: articles\\blackassign0008.txt\n",
      "Analyzing file: articles\\blackassign0009.txt\n",
      "Analyzing file: articles\\blackassign0010.txt\n",
      "Analyzing file: articles\\blackassign0011.txt\n",
      "Analyzing file: articles\\blackassign0012.txt\n",
      "Analyzing file: articles\\blackassign0013.txt\n",
      "Analyzing file: articles\\blackassign0014.txt\n",
      "Analyzing file: articles\\blackassign0015.txt\n",
      "Analyzing file: articles\\blackassign0016.txt\n",
      "Analyzing file: articles\\blackassign0017.txt\n",
      "Analyzing file: articles\\blackassign0018.txt\n",
      "Analyzing file: articles\\blackassign0019.txt\n",
      "Analyzing file: articles\\blackassign0020.txt\n",
      "Analyzing file: articles\\blackassign0021.txt\n",
      "Analyzing file: articles\\blackassign0022.txt\n",
      "Analyzing file: articles\\blackassign0023.txt\n",
      "Analyzing file: articles\\blackassign0024.txt\n",
      "Analyzing file: articles\\blackassign0025.txt\n",
      "Analyzing file: articles\\blackassign0026.txt\n",
      "Analyzing file: articles\\blackassign0027.txt\n",
      "Analyzing file: articles\\blackassign0028.txt\n",
      "Analyzing file: articles\\blackassign0029.txt\n",
      "Analyzing file: articles\\blackassign0030.txt\n",
      "Analyzing file: articles\\blackassign0031.txt\n",
      "Analyzing file: articles\\blackassign0032.txt\n",
      "Analyzing file: articles\\blackassign0033.txt\n",
      "Analyzing file: articles\\blackassign0034.txt\n",
      "Analyzing file: articles\\blackassign0035.txt\n",
      "Analyzing file: articles\\blackassign0037.txt\n",
      "Analyzing file: articles\\blackassign0038.txt\n",
      "Analyzing file: articles\\blackassign0039.txt\n",
      "Analyzing file: articles\\blackassign0040.txt\n",
      "Analyzing file: articles\\blackassign0041.txt\n",
      "Analyzing file: articles\\blackassign0042.txt\n",
      "Analyzing file: articles\\blackassign0043.txt\n",
      "Analyzing file: articles\\blackassign0044.txt\n",
      "Analyzing file: articles\\blackassign0045.txt\n",
      "Analyzing file: articles\\blackassign0046.txt\n",
      "Analyzing file: articles\\blackassign0047.txt\n",
      "Analyzing file: articles\\blackassign0048.txt\n",
      "Analyzing file: articles\\blackassign0050.txt\n",
      "Analyzing file: articles\\blackassign0051.txt\n",
      "Analyzing file: articles\\blackassign0052.txt\n",
      "Analyzing file: articles\\blackassign0053.txt\n",
      "Analyzing file: articles\\blackassign0054.txt\n",
      "Analyzing file: articles\\blackassign0055.txt\n",
      "Analyzing file: articles\\blackassign0056.txt\n",
      "Analyzing file: articles\\blackassign0057.txt\n",
      "Analyzing file: articles\\blackassign0058.txt\n",
      "Analyzing file: articles\\blackassign0059.txt\n",
      "Analyzing file: articles\\blackassign0060.txt\n",
      "Analyzing file: articles\\blackassign0061.txt\n",
      "Analyzing file: articles\\blackassign0062.txt\n",
      "Analyzing file: articles\\blackassign0063.txt\n",
      "Analyzing file: articles\\blackassign0064.txt\n",
      "Analyzing file: articles\\blackassign0065.txt\n",
      "Analyzing file: articles\\blackassign0066.txt\n",
      "Analyzing file: articles\\blackassign0067.txt\n",
      "Analyzing file: articles\\blackassign0068.txt\n",
      "Analyzing file: articles\\blackassign0069.txt\n",
      "Analyzing file: articles\\blackassign0070.txt\n",
      "Analyzing file: articles\\blackassign0071.txt\n",
      "Analyzing file: articles\\blackassign0072.txt\n",
      "Analyzing file: articles\\blackassign0073.txt\n",
      "Analyzing file: articles\\blackassign0074.txt\n",
      "Analyzing file: articles\\blackassign0075.txt\n",
      "Analyzing file: articles\\blackassign0076.txt\n",
      "Analyzing file: articles\\blackassign0077.txt\n",
      "Analyzing file: articles\\blackassign0078.txt\n",
      "Analyzing file: articles\\blackassign0079.txt\n",
      "Analyzing file: articles\\blackassign0080.txt\n",
      "Analyzing file: articles\\blackassign0081.txt\n",
      "Analyzing file: articles\\blackassign0082.txt\n",
      "Analyzing file: articles\\blackassign0083.txt\n",
      "Analyzing file: articles\\blackassign0084.txt\n",
      "Analyzing file: articles\\blackassign0085.txt\n",
      "Analyzing file: articles\\blackassign0086.txt\n",
      "Analyzing file: articles\\blackassign0087.txt\n",
      "Analyzing file: articles\\blackassign0088.txt\n",
      "Analyzing file: articles\\blackassign0089.txt\n",
      "Analyzing file: articles\\blackassign0090.txt\n",
      "Analyzing file: articles\\blackassign0091.txt\n",
      "Analyzing file: articles\\blackassign0092.txt\n",
      "Analyzing file: articles\\blackassign0093.txt\n",
      "Analyzing file: articles\\blackassign0094.txt\n",
      "Analyzing file: articles\\blackassign0095.txt\n",
      "Analyzing file: articles\\blackassign0096.txt\n",
      "Analyzing file: articles\\blackassign0097.txt\n",
      "Analyzing file: articles\\blackassign0098.txt\n",
      "Analyzing file: articles\\blackassign0099.txt\n",
      "Analyzing file: articles\\blackassign0100.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def store_results(output_file, url_id, analysis_results):\n",
    "    try:\n",
    "        # Load the existing data from the Excel file\n",
    "        df = pd.read_excel(output_file, engine='openpyxl')\n",
    "        \n",
    "        # Find the row corresponding to the current file_id\n",
    "        row_index = df[df['URL_ID'] == url_id].index\n",
    "        \n",
    "        if row_index.empty:\n",
    "            print(f\"URL_ID not found for file_id: {file_id}\")\n",
    "            return\n",
    "\n",
    "        row_index = row_index[0]  # Get the actual index value from the Index object\n",
    "        # Update the row with the analysis results\n",
    "        for key, value in analysis_results.items():\n",
    "            df.at[row_index, key] = value\n",
    "          \n",
    "        \n",
    "        # Save the updated DataFrame back to the Excel file\n",
    "        df.to_excel(output_file, index=False, engine='openpyxl')\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating the DataFrame for file_id: {file_id}\")\n",
    "        print(e)\n",
    "\n",
    "# Assuming the analyze_file function and other necessary functions are defined\n",
    "\n",
    "folder_path = 'articles'  \n",
    "output_file = 'Output Data Structure.xlsx' \n",
    "\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.startswith('blackassign') and file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f\"Analyzing file: {file_path}\")\n",
    "        results = analyze_file(file_path, stop_words, punctuation, positive_words, negative_words)\n",
    "        if results:\n",
    "            # Strip off the file extension if present\n",
    "            file_id = os.path.splitext(file_name)[0]\n",
    "            store_results(output_file, file_id, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405c971-68a8-4710-a88e-44a607ca2f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f88bc2-bd1f-4cb4-96b8-38494169a200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083cc24e-d75e-4371-a3b6-30476c0866e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a9c87-0f57-4004-b9d3-96f94f006e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
